# Model metadata
name = "qwen-3-8b"
description = "Qwen3 8B Model"
version = "1.0"
parameters = ["qwen-3-8b.zt"] 

# Model architecture details
[architecture]
type = "qwen3"
num_layers = 36
num_query_heads = 32
num_key_value_heads = 8
head_size = 128
hidden_size = 4096
intermediate_size = 12288
vocab_size = 151936
use_qkv_bias = false
rms_norm_eps = 1e-5

[architecture.rope]
theta = 1000000.0

# Tokenizer configuration
[tokenizer]
type = "bpe"
vocabulary_file = "qwen-3.vocab"
split_regex = "(?i:[sdmt]|ll|ve|re)|[^\\r\\n\\p{L}\\p{N}]?+\\p{L}++|\\p{N}{1,3}+| ?[^\\s\\p{L}\\p{N}]++[\\r\\n]*+|\\s++$|\\s*[\\r\\n]|\\s+(?!\\S)|\\s"
escape_non_printable = true

[tokenizer.special_tokens]
"<|endoftext|>" = 151643
"<|im_start|>" = 151644
"<|im_end|>" = 151645
"<|object_ref_start|>" = 151646
"<|object_ref_end|>" = 151647
"<|box_start|>" = 151648
"<|box_end|>" = 151649
"<|quad_start|>" = 151650
"<|quad_end|>" = 151651
"<|vision_start|>" = 151652
"<|vision_end|>" = 151653
"<|vision_pad|>" = 151654
"<|image_pad|>" = 151655
"<|video_pad|>" = 151656
"<tool_call>" = 151657
"</tool_call>" = 151658
"<|fim_prefix|>" = 151659
"<|fim_middle|>" = 151660
"<|fim_suffix|>" = 151661
"<|fim_pad|>" = 151662
"<|repo_name|>" = 151663
"<|file_sep|>" = 151664
"<tool_response>" = 151665
"</tool_response>" = 151666
"<think>" = 151667
"</think>" = 151668

# Prompt template configuration
[template]
type = "minijinja"
content = """
<|im_start|>system
{%- for m in messages if m.role == "system" %}
{{ m.content }}
{%- endfor %}<|im_end|>
{%- for m in messages if m.role != "system" %}
{%- if m.role == "user" %}
<|im_start|>user
{{ m.content }}<|im_end|>
{%- elif m.role == "assistant" %}
<|im_start|>assistant
{%- if m.reasoning_content %}<think>
{{ m.reasoning_content | trim }}
</think>
{%- endif -%}
{%- if m.tool_calls %}
{%- for tc in m.tool_calls %}
<tool_call>
{"name":"{{ tc.name }}","arguments": {{ tc.arguments | tojson }}}
</tool_call>
{%- endfor %}
{%- else %}
{{ m.content }}
{%- endif -%}<|im_end|>
{%- elif m.role == "tool" %}
<|im_start|>user
<tool_response>
{{ m.content }}
</tool_response><|im_end|>
{%- else %}
<|im_start|>user
{{ m.content }}<|im_end|>
{%- endif %}
{%- endfor %}
{%- if add_generation_prompt %}
<|im_start|>assistant
{%- endif %}
"""
stop_tokens = ["<|im_end|>", "<|im_start|>", "<|endoftext|>"]

[source]
"qwen-3-8b.zt" = "https://huggingface.co/pie-project/qwen-3-8b/resolve/main/qwen-3-8b.zt"
"qwen-3.vocab" = "https://huggingface.co/pie-project/qwen-3-8b/resolve/main/qwen-3.vocab"
