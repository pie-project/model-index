# Model metadata
name = "deepseek-r1-distill-qwen-2-32b"
description = "DeepSeek-R1 Distilled Qwen 2 32B Model"
version = "1.0"
parameters = ["deepseek-r1-distill-qwen-2-32b.zt"]

# Model architecture details
[architecture]
type = "qwen2"
num_layers = 64
num_query_heads = 40
num_key_value_heads = 8
head_size = 128
hidden_size = 5120
intermediate_size = 27648
vocab_size = 152064
use_qkv_bias = true
rms_norm_eps = 1e-5

[architecture.rope]
theta = 1000000.0

# Tokenizer configuration
[tokenizer]
type = "bpe"
vocabulary_file = "deepseek-r1-distill-qwen-2.vocab"
split_regex = "(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+"
escape_non_printable = true

[tokenizer.special_tokens]
"<｜begin▁of▁sentence｜>" = 151646
"<｜end▁of▁sentence｜>" = 151643

# Prompt template configuration for reasoning model
[template]
type = "minijinja"
content = """{%- if not add_generation_prompt is defined -%}
	{%- set add_generation_prompt = false -%}
{%- endif -%}
{%- if not begin_of_sequence is defined -%}
	{%- set begin_of_sequence = false -%}
{%- endif -%}
{%- if begin_of_sequence -%}
	{%- set bos_token = "<｜begin▁of▁sentence｜>" -%}
{%- else -%}
    {%- set bos_token = "" -%}
{%- endif -%}
{%- set ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt="") -%}
{%- for message in messages -%}
	{%- if message["role"] == "system" -%}
		{%- set ns.system_prompt = message["content"] -%}
	{%- endif -%}
{%- endfor -%}
{{- bos_token -}}
{{- ns.system_prompt -}}
{%- for message in messages -%}
	{%- if message["role"] == "user" -%}
		{%- set ns.is_tool = false -%}
		{{- "<｜User｜>" + message["content"] -}}
	{%- endif -%}
	{%- if message["role"] == "assistant" and message["content"] is none -%}
		{%- set ns.is_tool = false -%}
		{%- for tool in message["tool_calls"] -%}
			{%- if not ns.is_first -%}
				{{- "<｜Assistant｜><｜tool▁calls▁begin｜><｜tool▁call▁begin｜>" + tool["type"] + "<｜tool▁sep｜>" + tool["function"]["name"] + "\n" + "```json" + "\n" + tool["function"]["arguments"] + "\n" + "```" + "<｜tool▁call▁end｜>" -}}
				{%- set ns.is_first = true -%}
			{%- else -%}
				{{- "\n" + "<｜tool▁call▁begin｜>" + tool["type"] + "<｜tool▁sep｜>" + tool["function"]["name"] + "\n" + "```json" + "\n" + tool["function"]["arguments"] + "\n" + "```" + "<｜tool▁call▁end｜>" -}}
				{{- "<｜tool▁calls▁end｜><｜end▁of▁sentence｜>" -}}
			{%- endif -%}
		{%- endfor -%}
	{%- endif -%}
	{%- if message["role"] == "assistant" and message["content"] is not none -%}
		{%- if ns.is_tool -%}
			{{- "<｜tool▁outputs▁end｜>" + message["content"] + "<｜end▁of▁sentence｜>" -}}
			{%- set ns.is_tool = false -%}
		{%- else -%}
			{%- set content = message["content"] -%}
			{%- if "</think>" in content -%}
				{%- set content = content.split("</think>")[-1] -%}
			{%- endif -%}
			{{- "<｜Assistant｜>" + content + "<｜end▁of▁sentence｜>" -}}
		{%- endif -%}
	{%- endif -%}
	{%- if message["role"] == "tool" -%}
		{%- set ns.is_tool = true -%}
		{%- if ns.is_output_first -%}
			{{- "<｜tool▁outputs▁begin｜><｜tool▁output▁begin｜>" + message["content"] + "<｜tool▁output▁end｜>" -}}
			{%- set ns.is_output_first = false -%}
		{%- else -%}
			{{- "\n<｜tool▁output▁begin｜>" + message["content"] + "<｜tool▁output▁end｜>" -}}
		{%- endif -%}
	{%- endif -%}
{%- endfor -%}
{%- if ns.is_tool -%}
	{{- "<｜tool▁outputs▁end｜>" -}}
{%- endif -%}
{%- if add_generation_prompt and not ns.is_tool -%}
	{{- "<｜Assistant｜><think>\n" -}}
{%- endif -%}
"""
stop_tokens = ["<｜end▁of▁sentence｜>"]


[source]
"deepseek-r1-distill-qwen-2-32b.zt" = "https://huggingface.co/pie-project/deepseek-r1-distill-qwen-2-32b/resolve/main/deepseek-r1-distill-qwen-2-32b.zt"
"deepseek-r1-distill-qwen-2.vocab" = "https://huggingface.co/pie-project/deepseek-r1-distill-qwen-2-32b/resolve/main/deepseek-r1-distill-qwen-2.vocab"
