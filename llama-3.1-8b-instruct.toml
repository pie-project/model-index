# Model metadata
name = "llama-3.1-8b-instruct"
description = "Meta Llama 3.1 8B Instruct Model"
version = "1.0"
license = "Llama"
traits = ["input_text", "output_text", "tokenize"]
parameters = ["llama-3.1-8b-instruct.zt"] 


# Model architecture details
[architecture]
type = "l4ma"
num_layers = 32
num_query_heads = 32
num_key_value_heads = 8
head_size = 128
hidden_size = 4096
intermediate_size = 14336
vocab_size = 128256
use_qkv_bias = false
rms_norm_eps = 1e-5

[architecture.rope]
factor = 8.0
high_frequency_factor = 4.0
low_frequency_factor = 1.0
theta = 500000.0

# Tokenizer configuration
[tokenizer]
type = "bpe"
vocabulary_file = "llama-3.1.vocab"
split_regex = "(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+"
escape_non_printable = false

[tokenizer.special_tokens]
"<|begin_of_text|>" = 128000
"<|end_of_text|>" = 128001
"<|start_header_id|>" = 128006
"<|end_header_id|>" = 128007
"<|eot_id|>" = 128009

# Prompt template configuration
[template]
type = "minijinja"
content = """
<|start_header_id|>system<|end_header_id|>{{ "\n" }}
{%- for m in messages if m.role == "system" %}
{{ m.content }}
{%- endfor %}<|eot_id|>
{%- for m in messages if m.role != "system" %}
{%- set hdr = (
    "user" if m.role=="user" else
    "assistant" if m.role=="assistant" else
    "ipython" if m.role=="tool" else "user"
) -%}
<|start_header_id|>{{ hdr }}<|end_header_id|>{{ "\n" }}
{%- if m.role == "assistant" and m.reasoning_content %}<think>
{{ m.reasoning_content | trim }}
</think>
{%- endif -%}
{%- if m.role == "assistant" and m.tool_calls %}
{%- for tc in m.tool_calls %}
{"name":"{{ tc.name }}","parameters": {{ tc.arguments | tojson }}}
{%- endfor %}
{%- else %}
{{ m.content }}
{%- endif %}
<|eot_id|>
{%- endfor %}
{%- if add_generation_prompt and (messages | length == 0 or (messages | last).role != "assistant") %}<|start_header_id|>assistant<|end_header_id|>
{%- endif %}
"""

[source]
"llama-3.1-8b-instruct.zt" = "https://huggingface.co/pie-project/llama-3.1-8b-instruct/resolve/main/llama-3.1-8b-instruct.zt"
"llama-3.1.vocab" = "https://huggingface.co/pie-project/llama-3.2-3b-instruct/resolve/main/llama-3.2.vocab"